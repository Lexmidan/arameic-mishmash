{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same task as in `AutoencoderMNIST.ipynb`, this time implemented in lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = transforms.ToTensor()) #\n",
    "# dataset, _ =\\\n",
    "#                 torch.utils.data.random_split(dataset, (int(0.04*len(dataset)), int(0.96*len(dataset))))\n",
    "\n",
    "train_set, test_set, valid_set =\\\n",
    "                torch.utils.data.random_split(dataset, (int(0.7*len(dataset)), int(0.15*len(dataset)), int(0.15*len(dataset))))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_set, batch_size = 32)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = valid_set, batch_size = 32)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfeatures = 28*28 #size of the encoder input layer\n",
    "Layers=[128,64,36,18] #sizes of inner layers\n",
    "NTargets=10 #size of the encoder output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_AE(pl.LightningModule): \n",
    "\n",
    "### Model ###\n",
    "    def __init__(self, Nfeatures, Layers, Ntargets):\n",
    "        super(MNIST_AE, self).__init__() # TODO: if not \"cannot assign module before Module.__init__() call\"\n",
    "        # Initialize layers\n",
    "        self.encoderIn = torch.nn.Linear(Nfeatures, Layers[0]) #first layer 28*28 -> 128\n",
    "        self.encoderl1 = torch.nn.Linear(Layers[0], Layers[1])\n",
    "        self.encoderl2 = torch.nn.Linear(Layers[1], Layers[2])\n",
    "        self.encoderl3 = torch.nn.Linear(Layers[2], Layers[3])\n",
    "        self.encoderOut = torch.nn.Linear(Layers[3], Ntargets)\n",
    "\n",
    "        self.decoderIn = torch.nn.Linear(Ntargets, Layers[3]) #f\n",
    "        self.decoderl1 = torch.nn.Linear(Layers[3], Layers[2])\n",
    "        self.decoderl2 = torch.nn.Linear(Layers[2], Layers[1])\n",
    "        self.decoderl3 = torch.nn.Linear(Layers[1], Layers[0])\n",
    "        self.decoderOut = torch.nn.Linear(Layers[0], Nfeatures)\n",
    "        # TODO: better place to define mse_loss\n",
    "        self.mse_loss = torch.nn.MSELoss(reduction = 'mean')\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.encoderIn(x))\n",
    "        x = torch.relu(self.encoderl1(x))\n",
    "        x = torch.relu(self.encoderl2(x))\n",
    "        x = torch.relu(self.encoderl3(x))\n",
    "        x = self.encoderOut(x)\n",
    "        x = torch.relu(self.decoderIn(x))\n",
    "        x = torch.relu(self.decoderl1(x))\n",
    "        x = torch.relu(self.decoderl2(x))\n",
    "        x = torch.relu(self.decoderl3(x))\n",
    "        x = self.decoderOut(x)\n",
    "        return x\n",
    "\n",
    "### The Optimizer ### \n",
    "    def configure_optimizers(self):\n",
    "        #optimizer = torch.optim.Adam(self.parameters(), lr=0.05)#l_rate) # TODO: should be a parameter\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                             lr = 1e-2,\n",
    "                             weight_decay = 1e-8)\n",
    "        return optimizer\n",
    "\n",
    "### Training ### \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, label = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        # Evaluate physical model using data scaling\n",
    "        logits = self.forward(images)\n",
    "        # Evaluate loss comparing to the kinetic heat flux in y\n",
    "        loss = self.mse_loss(logits, images)\n",
    "        # Add logging\n",
    "        self.log(\"train_loss\", loss)\n",
    "        logs = {'loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, label = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        logits = self.forward(images)\n",
    "        loss = self.mse_loss(logits, images)\n",
    "        self.log(\"test_loss\", loss)\n",
    "### Validation ### \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, label = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        # Evaluate physical model using data scaling\n",
    "        logits = self.forward(images)\n",
    "        # Evaluate loss comparing to the kinetic heat flux in y\n",
    "        loss = self.mse_loss(logits, images)\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "    # Define validation epoch end\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"validation_epoch_average\", avg_loss)\n",
    "        self.validation_step_outputs.clear()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MNIST_AE(Nfeatures, Layers, NTargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.utilities.model_summary.ModelSummary(model,max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in model.state_dict():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "trainer = pl.Trainer(max_epochs = 7)\n",
    "trainer.fit(model, train_loader, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(*args): #just plotting the result\n",
    "\n",
    "    n = min([x.shape[0] for x in args]) #n=5\n",
    "    \n",
    "    plt.figure(figsize=(2*n, 2*len(args))) #10 na 4\n",
    "    for j in range(n): #j [1,2,3,4,5]\n",
    "        for i in range(len(args)): #i [1,2]\n",
    "            img=args[i][j].reshape(-1,28,28).detach().numpy()\n",
    "            ax = plt.subplot(len(args), n, i*n + j + 1) #arguments: nrows, ncols, index\n",
    "            plt.imshow(img[0])\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "xbatch, ybatch =next(iter(test_loader))\n",
    "xbatch=xbatch.reshape(-1,28*28)\n",
    "a=[model(x) for x in xbatch[:5]]\n",
    "a=torch.stack(a, dim=0)\n",
    "\n",
    "plot_digits(xbatch[:5], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_result = trainer.test(model, dataloaders=validation_loader, verbose=False)\n",
    "test_result = trainer.test(model, dataloaders=test_loader, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
