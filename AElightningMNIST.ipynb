{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same task as in `AutoencoderMNIST.ipynb`, this time implemented in lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root = \"./data\",\n",
    "                         train = True,\n",
    "                         download = True,\n",
    "                         transform = transforms.ToTensor()) #\n",
    "\n",
    "\n",
    "train_set, test_set, valid_set =\\\n",
    "                torch.utils.data.random_split(dataset, (int(0.7*len(dataset)), int(0.15*len(dataset)), int(0.15*len(dataset))))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_set, batch_size = 32)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = valid_set, batch_size = 32)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_set, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 6, 1, 9, 3, 0, 4, 2, 9, 6, 8, 8, 6, 2, 7, 5, 4, 3, 1, 2, 1, 7, 2, 0,\n",
       "        4, 6, 0, 5, 3, 3, 8, 3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y=  next(iter(train_loader))\n",
    "x.reshape(-1, 28*28).size()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfeatures = 28*28 #size of the encoder input layer\n",
    "Layers=[128,64,36,18] #sizes of inner layers\n",
    "NTargets=10 #size of the encoder output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_AE(pl.LightningModule): \n",
    "\n",
    "### Model ###\n",
    "    def __init__(self, Nfeatures, Layers, Ntargets):\n",
    "        super(MNIST_AE, self).__init__() # TODO: if not \"cannot assign module before Module.__init__() call\"\n",
    "        # Initialize layers\n",
    "        self.encoderIn = torch.nn.Linear(Nfeatures, Layers[0]) #first layer 28*28 -> 128\n",
    "        self.encoderl1 = torch.nn.Linear(Layers[0], Layers[1])\n",
    "        self.encoderl2 = torch.nn.Linear(Layers[1], Layers[2])\n",
    "        self.encoderl3 = torch.nn.Linear(Layers[2], Layers[3])\n",
    "        self.encoderOut = torch.nn.Linear(Layers[3], Ntargets)\n",
    "\n",
    "        self.decoderIn = torch.nn.Linear(Ntargets, Layers[3]) #f\n",
    "        self.decoderl1 = torch.nn.Linear(Layers[3], Layers[2])\n",
    "        self.decoderl2 = torch.nn.Linear(Layers[2], Layers[1])\n",
    "        self.decoderl3 = torch.nn.Linear(Layers[1], Layers[0])\n",
    "        self.decoderOut = torch.nn.Linear(Layers[0], Nfeatures)\n",
    "        # TODO: better place to define mse_loss\n",
    "        self.mse_loss = torch.nn.MSELoss(reduction = 'mean')\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.encoderIn(x))\n",
    "        x = torch.relu(self.encoderl1(x))\n",
    "        x = torch.relu(self.encoderl2(x))\n",
    "        x = torch.relu(self.encoderl3(x))\n",
    "        x = self.encoderOut(x)\n",
    "        x = torch.relu(self.decoderIn(x))\n",
    "        x = torch.relu(self.decoderl1(x))\n",
    "        x = torch.relu(self.decoderl2(x))\n",
    "        x = torch.relu(self.decoderl3(x))\n",
    "        x = self.decoderOut(x)\n",
    "        return x\n",
    "\n",
    "### The Optimizer ### \n",
    "    def configure_optimizers(self):\n",
    "        #optimizer = torch.optim.Adam(self.parameters(), lr=0.05)#l_rate) # TODO: should be a parameter\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=1e-5)#l_rate) # TODO: should be a parameter\n",
    "        return optimizer\n",
    "\n",
    "### Training ### \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, label = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        # Evaluate physical model using data scaling\n",
    "        logits = self.forward(images)\n",
    "        # Evaluate loss comparing to the kinetic heat flux in y\n",
    "        loss = self.mse_loss(logits, images)\n",
    "        # Add logging\n",
    "        logs = {'loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "\n",
    "### Validation ### \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, label = batch\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        # Evaluate physical model using data scaling\n",
    "        logits = self.forward(images)\n",
    "        # Evaluate loss comparing to the kinetic heat flux in y\n",
    "        loss = self.mse_loss(logits, images)\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "    # Define validation epoch end\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.log(\"validation_epoch_average\", avg_loss)\n",
    "        self.validation_step_outputs.clear()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MNIST_AE(Nfeatures, Layers, NTargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   | Name       | Type    | Params\n",
       "----------------------------------------\n",
       "0  | encoderIn  | Linear  | 100 K \n",
       "1  | encoderl1  | Linear  | 8.3 K \n",
       "2  | encoderl2  | Linear  | 2.3 K \n",
       "3  | encoderl3  | Linear  | 666   \n",
       "4  | encoderOut | Linear  | 190   \n",
       "5  | decoderIn  | Linear  | 198   \n",
       "6  | decoderl1  | Linear  | 684   \n",
       "7  | decoderl2  | Linear  | 2.4 K \n",
       "8  | decoderl3  | Linear  | 8.3 K \n",
       "9  | decoderOut | Linear  | 101 K \n",
       "10 | mse_loss   | MSELoss | 0     \n",
       "----------------------------------------\n",
       "224 K     Trainable params\n",
       "0         Non-trainable params\n",
       "224 K     Total params\n",
       "0.899     Total estimated model params size (MB)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.utilities.model_summary.ModelSummary(model,max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoderIn.weight\n",
      "encoderIn.bias\n",
      "encoderl1.weight\n",
      "encoderl1.bias\n",
      "encoderl2.weight\n",
      "encoderl2.bias\n",
      "encoderl3.weight\n",
      "encoderl3.bias\n",
      "encoderOut.weight\n",
      "encoderOut.bias\n",
      "decoderIn.weight\n",
      "decoderIn.bias\n",
      "decoderl1.weight\n",
      "decoderl1.bias\n",
      "decoderl2.weight\n",
      "decoderl2.bias\n",
      "decoderl3.weight\n",
      "decoderl3.bias\n",
      "decoderOut.weight\n",
      "decoderOut.bias\n"
     ]
    }
   ],
   "source": [
    "for name in model.state_dict():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name       | Type    | Params\n",
      "----------------------------------------\n",
      "0  | encoderIn  | Linear  | 100 K \n",
      "1  | encoderl1  | Linear  | 8.3 K \n",
      "2  | encoderl2  | Linear  | 2.3 K \n",
      "3  | encoderl3  | Linear  | 666   \n",
      "4  | encoderOut | Linear  | 190   \n",
      "5  | decoderIn  | Linear  | 198   \n",
      "6  | decoderl1  | Linear  | 684   \n",
      "7  | decoderl2  | Linear  | 2.4 K \n",
      "8  | decoderl3  | Linear  | 8.3 K \n",
      "9  | decoderOut | Linear  | 101 K \n",
      "10 | mse_loss   | MSELoss | 0     \n",
      "----------------------------------------\n",
      "224 K     Trainable params\n",
      "0         Non-trainable params\n",
      "224 K     Total params\n",
      "0.899     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501fe2e361354e0d8ab504310f4d2334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7248bd5a4e458c97ad2eaa8409adcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53a173a01324aceae94601e24fdc2de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d70f3dbef3f4855a241eedcbe137025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f9d63284464a2996ecb4c6ff105998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2310c065895d4ac8b71f9321e54397cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da76f0063df2489ebb8c903b177abe98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_digits(*args): #just plotting the result\n",
    "\n",
    "    n = min([x.shape[0] for x in args]) #n=5\n",
    "    \n",
    "    plt.figure(figsize=(2*n, 2*len(args))) #10 na 4\n",
    "    for j in range(n): #j [1,2,3,4,5]\n",
    "        for i in range(len(args)): #i [1,2]\n",
    "            img=args[i][j].reshape(-1,28,28).detach().numpy()\n",
    "            ax = plt.subplot(len(args), n, i*n + j + 1) #arguments: nrows, ncols, index\n",
    "            plt.imshow(img[0])\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "xbatch, ybatch =next(iter(test_loader))\n",
    "xbatch=xbatch.reshape(-1,28*28)\n",
    "a=[model(x) for x in xbatch[:5]]\n",
    "a=torch.stack(a, dim=0)\n",
    "\n",
    "plot_digits(xbatch[:5], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aleks\\Projects\\arameic-mishmash\\AElightningMNIST.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aleks/Projects/arameic-mishmash/AElightningMNIST.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtensorboard\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2432\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2431\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2432\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2434\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2435\u001b[0m \u001b[39m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2436\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m module_str:\n\u001b[0;32m     32\u001b[0m     \u001b[39mraise\u001b[39;00m UsageError(\u001b[39m'\u001b[39m\u001b[39mMissing module name.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39mextension_manager\u001b[39m.\u001b[39mload_extension(module_str)\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39malready loaded\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m extension is already loaded. To reload it, use:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m module_str)\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\IPython\\core\\extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[39mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_extension(module_str)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\IPython\\core\\extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmodules:\n\u001b[1;32m---> 91\u001b[0m         mod \u001b[39m=\u001b[39m import_module(module_str)\n\u001b[0;32m     92\u001b[0m     mod \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[module_str]\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[1;32mc:\\Users\\aleks\\anaconda3\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
